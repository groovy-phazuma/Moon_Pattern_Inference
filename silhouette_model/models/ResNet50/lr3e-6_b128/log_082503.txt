[20231207-082837] [INFO] Epoch: 1, train_loss: 6.8650, val_loss: 6.8326, train_acc: 0.0010, val_acc: 0.0013
[20231207-082837] [INFO] elapsed_time: 3.53 min
[20231207-083205] [INFO] Epoch: 2, train_loss: 6.7978, val_loss: 6.7741, train_acc: 0.0020, val_acc: 0.0036
[20231207-083205] [INFO] elapsed_time: 7.00 min
[20231207-083534] [INFO] Epoch: 3, train_loss: 6.7321, val_loss: 6.7083, train_acc: 0.0057, val_acc: 0.0066
[20231207-083534] [INFO] elapsed_time: 10.48 min
[20231207-083902] [INFO] Epoch: 4, train_loss: 6.6556, val_loss: 6.6270, train_acc: 0.0065, val_acc: 0.0092
[20231207-083902] [INFO] elapsed_time: 13.95 min
[20231207-084230] [INFO] Epoch: 5, train_loss: 6.5662, val_loss: 6.5391, train_acc: 0.0099, val_acc: 0.0106
[20231207-084230] [INFO] elapsed_time: 17.42 min
[20231207-084558] [INFO] Epoch: 6, train_loss: 6.4720, val_loss: 6.4153, train_acc: 0.0111, val_acc: 0.0128
[20231207-084558] [INFO] elapsed_time: 20.87 min
[20231207-084926] [INFO] Epoch: 7, train_loss: 6.3856, val_loss: 6.3199, train_acc: 0.0139, val_acc: 0.0143
[20231207-084926] [INFO] elapsed_time: 24.35 min
[20231207-085254] [INFO] Epoch: 8, train_loss: 6.2920, val_loss: 6.2324, train_acc: 0.0175, val_acc: 0.0155
[20231207-085254] [INFO] elapsed_time: 27.81 min
[20231207-085621] [INFO] Epoch: 9, train_loss: 6.2128, val_loss: 6.1486, train_acc: 0.0151, val_acc: 0.0179
[20231207-085621] [INFO] elapsed_time: 31.27 min
[20231207-085948] [INFO] Epoch: 10, train_loss: 6.1460, val_loss: 6.0766, train_acc: 0.0194, val_acc: 0.0200
[20231207-085948] [INFO] elapsed_time: 34.72 min
[20231207-090316] [INFO] Epoch: 11, train_loss: 6.0856, val_loss: 6.0125, train_acc: 0.0207, val_acc: 0.0237
[20231207-090316] [INFO] elapsed_time: 38.18 min
[20231207-090643] [INFO] Epoch: 12, train_loss: 6.0334, val_loss: 5.9686, train_acc: 0.0241, val_acc: 0.0250
[20231207-090643] [INFO] elapsed_time: 41.64 min
[20231207-091011] [INFO] Epoch: 13, train_loss: 5.9925, val_loss: 5.9153, train_acc: 0.0259, val_acc: 0.0247
[20231207-091011] [INFO] elapsed_time: 45.09 min
[20231207-091339] [INFO] Epoch: 14, train_loss: 5.9523, val_loss: 5.8723, train_acc: 0.0248, val_acc: 0.0274
[20231207-091339] [INFO] elapsed_time: 48.56 min
[20231207-091706] [INFO] Epoch: 15, train_loss: 5.9064, val_loss: 5.8318, train_acc: 0.0262, val_acc: 0.0295
[20231207-091706] [INFO] elapsed_time: 52.02 min
[20231207-092034] [INFO] Epoch: 16, train_loss: 5.8710, val_loss: 5.7911, train_acc: 0.0271, val_acc: 0.0302
[20231207-092034] [INFO] elapsed_time: 55.48 min
[20231207-092402] [INFO] Epoch: 17, train_loss: 5.8278, val_loss: 5.7425, train_acc: 0.0290, val_acc: 0.0322
[20231207-092402] [INFO] elapsed_time: 58.95 min
[20231207-092730] [INFO] Epoch: 18, train_loss: 5.7896, val_loss: 5.6929, train_acc: 0.0349, val_acc: 0.0358
[20231207-092730] [INFO] elapsed_time: 62.41 min
[20231207-093058] [INFO] Epoch: 19, train_loss: 5.7546, val_loss: 5.6462, train_acc: 0.0349, val_acc: 0.0406
[20231207-093058] [INFO] elapsed_time: 65.88 min
[20231207-093426] [INFO] Epoch: 20, train_loss: 5.6980, val_loss: 5.5950, train_acc: 0.0361, val_acc: 0.0411
[20231207-093426] [INFO] elapsed_time: 69.35 min
[20231207-093754] [INFO] Epoch: 21, train_loss: 5.6562, val_loss: 5.5639, train_acc: 0.0390, val_acc: 0.0426
[20231207-093754] [INFO] elapsed_time: 72.81 min
[20231207-094122] [INFO] Epoch: 22, train_loss: 5.6224, val_loss: 5.5182, train_acc: 0.0380, val_acc: 0.0478
[20231207-094122] [INFO] elapsed_time: 76.27 min
[20231207-094450] [INFO] Epoch: 23, train_loss: 5.5872, val_loss: 5.4719, train_acc: 0.0434, val_acc: 0.0478
[20231207-094450] [INFO] elapsed_time: 79.74 min
[20231207-094817] [INFO] Epoch: 24, train_loss: 5.5397, val_loss: 5.4213, train_acc: 0.0427, val_acc: 0.0508
[20231207-094817] [INFO] elapsed_time: 83.20 min
[20231207-095145] [INFO] Epoch: 25, train_loss: 5.5028, val_loss: 5.3740, train_acc: 0.0439, val_acc: 0.0505
[20231207-095145] [INFO] elapsed_time: 86.66 min
[20231207-095512] [INFO] Epoch: 26, train_loss: 5.4582, val_loss: 5.3393, train_acc: 0.0470, val_acc: 0.0506
[20231207-095512] [INFO] elapsed_time: 90.11 min
[20231207-095839] [INFO] Epoch: 27, train_loss: 5.4199, val_loss: 5.2964, train_acc: 0.0478, val_acc: 0.0564
[20231207-095839] [INFO] elapsed_time: 93.57 min
[20231207-100207] [INFO] Epoch: 28, train_loss: 5.3753, val_loss: 5.2447, train_acc: 0.0506, val_acc: 0.0562
[20231207-100207] [INFO] elapsed_time: 97.03 min
[20231207-100535] [INFO] Epoch: 29, train_loss: 5.3278, val_loss: 5.2174, train_acc: 0.0534, val_acc: 0.0589
[20231207-100535] [INFO] elapsed_time: 100.49 min
[20231207-100904] [INFO] Epoch: 30, train_loss: 5.3065, val_loss: 5.1637, train_acc: 0.0509, val_acc: 0.0580
[20231207-100904] [INFO] elapsed_time: 103.98 min
[20231207-101231] [INFO] Epoch: 31, train_loss: 5.2607, val_loss: 5.1267, train_acc: 0.0584, val_acc: 0.0613
[20231207-101231] [INFO] elapsed_time: 107.44 min
[20231207-101559] [INFO] Epoch: 32, train_loss: 5.2233, val_loss: 5.0841, train_acc: 0.0580, val_acc: 0.0664
[20231207-101559] [INFO] elapsed_time: 110.89 min
[20231207-101927] [INFO] Epoch: 33, train_loss: 5.1832, val_loss: 5.0456, train_acc: 0.0581, val_acc: 0.0658
[20231207-101927] [INFO] elapsed_time: 114.35 min
[20231207-102254] [INFO] Epoch: 34, train_loss: 5.1501, val_loss: 5.0161, train_acc: 0.0558, val_acc: 0.0627
[20231207-102254] [INFO] elapsed_time: 117.82 min
[20231207-102622] [INFO] Epoch: 35, train_loss: 5.1077, val_loss: 4.9585, train_acc: 0.0660, val_acc: 0.0701
[20231207-102622] [INFO] elapsed_time: 121.28 min
[20231207-102950] [INFO] Epoch: 36, train_loss: 5.0736, val_loss: 4.9218, train_acc: 0.0646, val_acc: 0.0711
[20231207-102950] [INFO] elapsed_time: 124.75 min
[20231207-103318] [INFO] Epoch: 37, train_loss: 5.0271, val_loss: 4.8971, train_acc: 0.0647, val_acc: 0.0741
[20231207-103318] [INFO] elapsed_time: 128.21 min
[20231207-103645] [INFO] Epoch: 38, train_loss: 4.9808, val_loss: 4.8474, train_acc: 0.0702, val_acc: 0.0792
[20231207-103645] [INFO] elapsed_time: 131.67 min
[20231207-104013] [INFO] Epoch: 39, train_loss: 4.9630, val_loss: 4.8189, train_acc: 0.0677, val_acc: 0.0710
[20231207-104013] [INFO] elapsed_time: 135.13 min
[20231207-104341] [INFO] Epoch: 40, train_loss: 4.9119, val_loss: 4.7693, train_acc: 0.0742, val_acc: 0.0817
[20231207-104341] [INFO] elapsed_time: 138.60 min
[20231207-104709] [INFO] Epoch: 41, train_loss: 4.8704, val_loss: 4.7177, train_acc: 0.0764, val_acc: 0.0867
[20231207-104709] [INFO] elapsed_time: 142.07 min
[20231207-105037] [INFO] Epoch: 42, train_loss: 4.8330, val_loss: 4.6878, train_acc: 0.0743, val_acc: 0.0835
[20231207-105037] [INFO] elapsed_time: 145.53 min
[20231207-105406] [INFO] Epoch: 43, train_loss: 4.8077, val_loss: 4.6580, train_acc: 0.0764, val_acc: 0.0873
[20231207-105406] [INFO] elapsed_time: 149.01 min
[20231207-105734] [INFO] Epoch: 44, train_loss: 4.7422, val_loss: 4.6137, train_acc: 0.0833, val_acc: 0.0930
[20231207-105734] [INFO] elapsed_time: 152.48 min
[20231207-110102] [INFO] Epoch: 45, train_loss: 4.7124, val_loss: 4.5786, train_acc: 0.0860, val_acc: 0.0914
[20231207-110102] [INFO] elapsed_time: 155.94 min
[20231207-110430] [INFO] Epoch: 46, train_loss: 4.6781, val_loss: 4.5387, train_acc: 0.0862, val_acc: 0.0960
[20231207-110430] [INFO] elapsed_time: 159.40 min
[20231207-110757] [INFO] Epoch: 47, train_loss: 4.6394, val_loss: 4.5136, train_acc: 0.0878, val_acc: 0.0996
[20231207-110757] [INFO] elapsed_time: 162.86 min
[20231207-111125] [INFO] Epoch: 48, train_loss: 4.6176, val_loss: 4.4716, train_acc: 0.0936, val_acc: 0.1023
[20231207-111125] [INFO] elapsed_time: 166.33 min
[20231207-111452] [INFO] Epoch: 49, train_loss: 4.5753, val_loss: 4.4245, train_acc: 0.0947, val_acc: 0.1020
[20231207-111452] [INFO] elapsed_time: 169.78 min
[20231207-111821] [INFO] Epoch: 50, train_loss: 4.5100, val_loss: 4.3897, train_acc: 0.1033, val_acc: 0.1083
[20231207-111821] [INFO] elapsed_time: 173.26 min
[20231207-112149] [INFO] Epoch: 51, train_loss: 4.4956, val_loss: 4.3953, train_acc: 0.1039, val_acc: 0.0980
[20231207-112149] [INFO] elapsed_time: 176.72 min
[20231207-112516] [INFO] Epoch: 52, train_loss: 4.4780, val_loss: 4.3298, train_acc: 0.1016, val_acc: 0.1161
[20231207-112516] [INFO] elapsed_time: 180.18 min
[20231207-112844] [INFO] Epoch: 53, train_loss: 4.4233, val_loss: 4.2809, train_acc: 0.1087, val_acc: 0.1129
[20231207-112844] [INFO] elapsed_time: 183.64 min
[20231207-113212] [INFO] Epoch: 54, train_loss: 4.3839, val_loss: 4.2604, train_acc: 0.1144, val_acc: 0.1094
[20231207-113212] [INFO] elapsed_time: 187.11 min
[20231207-113539] [INFO] Epoch: 55, train_loss: 4.3614, val_loss: 4.2160, train_acc: 0.1089, val_acc: 0.1212
[20231207-113539] [INFO] elapsed_time: 190.56 min
[20231207-113907] [INFO] Epoch: 56, train_loss: 4.3367, val_loss: 4.1792, train_acc: 0.1153, val_acc: 0.1268
[20231207-113907] [INFO] elapsed_time: 194.02 min
[20231207-114235] [INFO] Epoch: 57, train_loss: 4.2877, val_loss: 4.1797, train_acc: 0.1173, val_acc: 0.1149
[20231207-114235] [INFO] elapsed_time: 197.50 min
[20231207-114603] [INFO] Epoch: 58, train_loss: 4.2436, val_loss: 4.1103, train_acc: 0.1291, val_acc: 0.1310
[20231207-114603] [INFO] elapsed_time: 200.96 min
[20231207-114931] [INFO] Epoch: 59, train_loss: 4.2174, val_loss: 4.0751, train_acc: 0.1242, val_acc: 0.1332
[20231207-114931] [INFO] elapsed_time: 204.43 min
[20231207-115259] [INFO] Epoch: 60, train_loss: 4.2027, val_loss: 4.0342, train_acc: 0.1200, val_acc: 0.1421
[20231207-115259] [INFO] elapsed_time: 207.90 min
[20231207-115627] [INFO] Epoch: 61, train_loss: 4.1459, val_loss: 4.0005, train_acc: 0.1313, val_acc: 0.1497
[20231207-115627] [INFO] elapsed_time: 211.36 min
[20231207-115954] [INFO] Epoch: 62, train_loss: 4.1154, val_loss: 4.0110, train_acc: 0.1381, val_acc: 0.1429
[20231207-115954] [INFO] elapsed_time: 214.82 min
[20231207-120322] [INFO] Epoch: 63, train_loss: 4.0921, val_loss: 3.9587, train_acc: 0.1381, val_acc: 0.1488
[20231207-120322] [INFO] elapsed_time: 218.28 min
[20231207-120649] [INFO] Epoch: 64, train_loss: 4.0301, val_loss: 3.9027, train_acc: 0.1493, val_acc: 0.1578
[20231207-120649] [INFO] elapsed_time: 221.74 min
[20231207-121017] [INFO] Epoch: 65, train_loss: 4.0370, val_loss: 3.8912, train_acc: 0.1407, val_acc: 0.1596
[20231207-121017] [INFO] elapsed_time: 225.19 min
[20231207-121345] [INFO] Epoch: 66, train_loss: 3.9982, val_loss: 3.8721, train_acc: 0.1465, val_acc: 0.1562
[20231207-121345] [INFO] elapsed_time: 228.66 min
[20231207-121714] [INFO] Epoch: 67, train_loss: 3.9631, val_loss: 3.8306, train_acc: 0.1505, val_acc: 0.1598
[20231207-121714] [INFO] elapsed_time: 232.14 min
[20231207-122041] [INFO] Epoch: 68, train_loss: 3.9287, val_loss: 3.8063, train_acc: 0.1598, val_acc: 0.1676
[20231207-122041] [INFO] elapsed_time: 235.60 min
[20231207-122409] [INFO] Epoch: 69, train_loss: 3.8988, val_loss: 3.8200, train_acc: 0.1548, val_acc: 0.1445
[20231207-122409] [INFO] elapsed_time: 239.06 min
[20231207-122736] [INFO] Epoch: 70, train_loss: 3.8749, val_loss: 3.7133, train_acc: 0.1539, val_acc: 0.1844
[20231207-122736] [INFO] elapsed_time: 242.52 min
[20231207-123104] [INFO] Epoch: 71, train_loss: 3.8486, val_loss: 3.6868, train_acc: 0.1635, val_acc: 0.1834
[20231207-123104] [INFO] elapsed_time: 245.98 min
[20231207-123432] [INFO] Epoch: 72, train_loss: 3.8138, val_loss: 3.6617, train_acc: 0.1712, val_acc: 0.1891
[20231207-123432] [INFO] elapsed_time: 249.44 min
[20231207-123800] [INFO] Epoch: 73, train_loss: 3.7811, val_loss: 3.6561, train_acc: 0.1685, val_acc: 0.1814
[20231207-123800] [INFO] elapsed_time: 252.91 min
[20231207-124128] [INFO] Epoch: 74, train_loss: 3.7651, val_loss: 3.6002, train_acc: 0.1647, val_acc: 0.1917
[20231207-124128] [INFO] elapsed_time: 256.38 min
[20231207-124456] [INFO] Epoch: 75, train_loss: 3.7223, val_loss: 3.5999, train_acc: 0.1832, val_acc: 0.1833
[20231207-124456] [INFO] elapsed_time: 259.84 min
[20231207-124823] [INFO] Epoch: 76, train_loss: 3.6939, val_loss: 3.6125, train_acc: 0.1807, val_acc: 0.1849
[20231207-124823] [INFO] elapsed_time: 263.30 min
[20231207-125151] [INFO] Epoch: 77, train_loss: 3.6656, val_loss: 3.5597, train_acc: 0.1847, val_acc: 0.1955
[20231207-125151] [INFO] elapsed_time: 266.76 min
[20231207-125519] [INFO] Epoch: 78, train_loss: 3.6449, val_loss: 3.5110, train_acc: 0.1827, val_acc: 0.2017
[20231207-125519] [INFO] elapsed_time: 270.22 min
[20231207-125846] [INFO] Epoch: 79, train_loss: 3.6272, val_loss: 3.4816, train_acc: 0.1947, val_acc: 0.2003
[20231207-125846] [INFO] elapsed_time: 273.68 min
[20231207-130213] [INFO] Epoch: 80, train_loss: 3.6011, val_loss: 3.4481, train_acc: 0.1951, val_acc: 0.2099
[20231207-130213] [INFO] elapsed_time: 277.14 min
[20231207-130542] [INFO] Epoch: 81, train_loss: 3.5542, val_loss: 3.4262, train_acc: 0.1988, val_acc: 0.2123
[20231207-130542] [INFO] elapsed_time: 280.61 min
[20231207-130910] [INFO] Epoch: 82, train_loss: 3.5350, val_loss: 3.4513, train_acc: 0.1985, val_acc: 0.1924
[20231207-130910] [INFO] elapsed_time: 284.07 min
[20231207-131237] [INFO] Epoch: 83, train_loss: 3.5523, val_loss: 3.3832, train_acc: 0.1952, val_acc: 0.2172
[20231207-131237] [INFO] elapsed_time: 287.54 min
[20231207-131606] [INFO] Epoch: 84, train_loss: 3.5078, val_loss: 3.4520, train_acc: 0.2018, val_acc: 0.1880
[20231207-131606] [INFO] elapsed_time: 291.01 min
[20231207-131934] [INFO] Epoch: 85, train_loss: 3.4644, val_loss: 3.3512, train_acc: 0.2085, val_acc: 0.2164
[20231207-131934] [INFO] elapsed_time: 294.48 min
[20231207-132302] [INFO] Epoch: 86, train_loss: 3.4498, val_loss: 3.3385, train_acc: 0.2105, val_acc: 0.2125
[20231207-132302] [INFO] elapsed_time: 297.95 min
[20231207-132631] [INFO] Epoch: 87, train_loss: 3.4473, val_loss: 3.2905, train_acc: 0.2101, val_acc: 0.2300
[20231207-132631] [INFO] elapsed_time: 301.43 min
[20231207-132959] [INFO] Epoch: 88, train_loss: 3.4027, val_loss: 3.2801, train_acc: 0.2147, val_acc: 0.2318
[20231207-132959] [INFO] elapsed_time: 304.89 min
[20231207-133326] [INFO] Epoch: 89, train_loss: 3.3854, val_loss: 3.2863, train_acc: 0.2192, val_acc: 0.2254
[20231207-133326] [INFO] elapsed_time: 308.35 min
[20231207-133654] [INFO] Epoch: 90, train_loss: 3.3550, val_loss: 3.3206, train_acc: 0.2247, val_acc: 0.2118
[20231207-133654] [INFO] elapsed_time: 311.81 min
[20231207-134020] [INFO] Epoch: 91, train_loss: 3.3513, val_loss: 3.2210, train_acc: 0.2239, val_acc: 0.2379
[20231207-134020] [INFO] elapsed_time: 315.25 min
[20231207-134348] [INFO] Epoch: 92, train_loss: 3.3122, val_loss: 3.2064, train_acc: 0.2296, val_acc: 0.2380
[20231207-134348] [INFO] elapsed_time: 318.72 min
[20231207-134716] [INFO] Epoch: 93, train_loss: 3.2903, val_loss: 3.1984, train_acc: 0.2391, val_acc: 0.2365
[20231207-134716] [INFO] elapsed_time: 322.18 min
[20231207-135044] [INFO] Epoch: 94, train_loss: 3.2550, val_loss: 3.1565, train_acc: 0.2397, val_acc: 0.2443
[20231207-135044] [INFO] elapsed_time: 325.64 min
[20231207-135411] [INFO] Epoch: 95, train_loss: 3.2579, val_loss: 3.1785, train_acc: 0.2339, val_acc: 0.2294
[20231207-135411] [INFO] elapsed_time: 329.10 min
[20231207-135739] [INFO] Epoch: 96, train_loss: 3.2382, val_loss: 3.1873, train_acc: 0.2337, val_acc: 0.2352
[20231207-135739] [INFO] elapsed_time: 332.56 min
[20231207-140108] [INFO] Epoch: 97, train_loss: 3.2281, val_loss: 3.1004, train_acc: 0.2446, val_acc: 0.2506
[20231207-140108] [INFO] elapsed_time: 336.05 min
[20231207-140436] [INFO] Epoch: 98, train_loss: 3.1882, val_loss: 3.1056, train_acc: 0.2515, val_acc: 0.2492
[20231207-140436] [INFO] elapsed_time: 339.52 min
[20231207-140804] [INFO] Epoch: 99, train_loss: 3.1613, val_loss: 3.0824, train_acc: 0.2434, val_acc: 0.2494
[20231207-140804] [INFO] elapsed_time: 342.98 min
[20231207-141132] [INFO] Epoch: 100, train_loss: 3.1466, val_loss: 3.0441, train_acc: 0.2512, val_acc: 0.2628
[20231207-141132] [INFO] elapsed_time: 346.45 min
[20231207-141133] [INFO] argument
[20231207-141133] [INFO]   note: None
[20231207-141133] [INFO]   seed: 24771
[20231207-141133] [INFO]   dir_result: ResNet50/lr3e-6_b128
[20231207-141133] [INFO]   model_name: ResNet50
[20231207-141133] [INFO]   num_epoch: 100
[20231207-141133] [INFO]   batch_size: 128
[20231207-141133] [INFO]   lr: 3e-06
[20231207-141133] [INFO]   patience: 25
[20231207-141133] [INFO]   delta: 0.002
[20231207-141133] [INFO]   lr_min: 1e-05
[20231207-141133] [INFO]   warmup_t: 10
[20231207-141133] [INFO]   warmup_lr_init: 1e-05
[20231207-141133] [INFO] loss
[20231207-141133] [INFO]   training: True
[20231207-141133] [INFO]   reduction: mean
[20231207-141133] [INFO]   ignore_index: -100
[20231207-141133] [INFO]   label_smoothing: 0.0
[20231207-141133] [INFO] optimizer
[20231207-141133] [INFO]   defaults: {'lr': 3e-06, 'betas': (0.9, 0.999), 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False, 'maximize': False, 'foreach': None, 'capturable': False, 'differentiable': False, 'fused': None}
[20231207-141133] [INFO] scheduler
[20231207-141133] [INFO]   optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 3e-06
    lr: 9.79308269133979e-06
    maximize: False
    weight_decay: 0
)
[20231207-141133] [INFO]   param_group_field: lr
[20231207-141133] [INFO]   base_values: [3e-06]
[20231207-141133] [INFO]   metric: None
[20231207-141133] [INFO]   t_in_epochs: True
[20231207-141133] [INFO]   noise_range_t: None
[20231207-141133] [INFO]   noise_pct: 0.67
[20231207-141133] [INFO]   noise_type: normal
[20231207-141133] [INFO]   noise_std: 1.0
[20231207-141133] [INFO]   noise_seed: 42
[20231207-141133] [INFO]   t_initial: 100
[20231207-141133] [INFO]   lr_min: 1e-05
[20231207-141133] [INFO]   cycle_mul: 1.0
[20231207-141133] [INFO]   cycle_decay: 1.0
[20231207-141133] [INFO]   cycle_limit: 1
[20231207-141133] [INFO]   warmup_t: 10
[20231207-141133] [INFO]   warmup_lr_init: 1e-05
[20231207-141133] [INFO]   warmup_prefix: True
[20231207-141133] [INFO]   k_decay: 1.0
[20231207-141133] [INFO]   warmup_steps: [-7.000000000000001e-07]
