[20231206-031200] [INFO] Epoch: 1, train_loss: 6.8650, val_loss: 6.8326, train_acc: 0.0010, val_acc: 0.0013
[20231206-031200] [INFO] elapsed_time: 3.50 min
[20231206-031526] [INFO] Epoch: 2, train_loss: 6.7978, val_loss: 6.7741, train_acc: 0.0020, val_acc: 0.0036
[20231206-031526] [INFO] elapsed_time: 6.94 min
[20231206-031853] [INFO] Epoch: 3, train_loss: 6.6491, val_loss: 6.4268, train_acc: 0.0063, val_acc: 0.0112
[20231206-031853] [INFO] elapsed_time: 10.38 min
[20231206-032220] [INFO] Epoch: 4, train_loss: 6.1465, val_loss: 5.6066, train_acc: 0.0107, val_acc: 0.0202
[20231206-032220] [INFO] elapsed_time: 13.84 min
[20231206-032548] [INFO] Epoch: 5, train_loss: 5.4693, val_loss: 4.9646, train_acc: 0.0223, val_acc: 0.0439
[20231206-032548] [INFO] elapsed_time: 17.30 min
[20231206-032914] [INFO] Epoch: 6, train_loss: 4.9646, val_loss: 5.3026, train_acc: 0.0349, val_acc: 0.0319
[20231206-032914] [INFO] elapsed_time: 20.74 min
[20231206-033241] [INFO] Epoch: 7, train_loss: 4.7115, val_loss: 4.5148, train_acc: 0.0454, val_acc: 0.0656
[20231206-033241] [INFO] elapsed_time: 24.18 min
[20231206-033608] [INFO] Epoch: 8, train_loss: 4.3685, val_loss: 4.1459, train_acc: 0.0640, val_acc: 0.0776
[20231206-033608] [INFO] elapsed_time: 27.63 min
[20231206-033935] [INFO] Epoch: 9, train_loss: 4.1327, val_loss: 4.2875, train_acc: 0.0811, val_acc: 0.0771
[20231206-033935] [INFO] elapsed_time: 31.08 min
[20231206-034301] [INFO] Epoch: 10, train_loss: 4.0855, val_loss: 4.1792, train_acc: 0.0830, val_acc: 0.0849
[20231206-034301] [INFO] elapsed_time: 34.51 min
[20231206-034627] [INFO] Epoch: 11, train_loss: 3.9737, val_loss: 3.9991, train_acc: 0.0986, val_acc: 0.1103
[20231206-034627] [INFO] elapsed_time: 37.95 min
[20231206-034954] [INFO] Epoch: 12, train_loss: 3.8629, val_loss: 3.9342, train_acc: 0.1077, val_acc: 0.1153
[20231206-034954] [INFO] elapsed_time: 41.40 min
[20231206-035322] [INFO] Epoch: 13, train_loss: 3.6828, val_loss: 4.3773, train_acc: 0.1281, val_acc: 0.0727
[20231206-035322] [INFO] elapsed_time: 44.86 min
[20231206-035649] [INFO] Epoch: 14, train_loss: 3.6131, val_loss: 3.6235, train_acc: 0.1404, val_acc: 0.1447
[20231206-035649] [INFO] elapsed_time: 48.32 min
[20231206-040016] [INFO] Epoch: 15, train_loss: 3.4434, val_loss: 3.7237, train_acc: 0.1520, val_acc: 0.1362
[20231206-040016] [INFO] elapsed_time: 51.76 min
[20231206-040343] [INFO] Epoch: 16, train_loss: 3.3451, val_loss: 3.4819, train_acc: 0.1712, val_acc: 0.1719
[20231206-040343] [INFO] elapsed_time: 55.21 min
[20231206-040710] [INFO] Epoch: 17, train_loss: 3.2640, val_loss: 3.5689, train_acc: 0.1776, val_acc: 0.1573
[20231206-040710] [INFO] elapsed_time: 58.65 min
[20231206-041037] [INFO] Epoch: 18, train_loss: 3.2291, val_loss: 3.4146, train_acc: 0.1903, val_acc: 0.1822
[20231206-041037] [INFO] elapsed_time: 62.11 min
[20231206-041403] [INFO] Epoch: 19, train_loss: 3.1217, val_loss: 3.6877, train_acc: 0.2020, val_acc: 0.1566
[20231206-041403] [INFO] elapsed_time: 65.55 min
[20231206-041730] [INFO] Epoch: 20, train_loss: 3.0540, val_loss: 3.3672, train_acc: 0.2171, val_acc: 0.1900
[20231206-041730] [INFO] elapsed_time: 69.00 min
[20231206-042057] [INFO] Epoch: 21, train_loss: 2.9824, val_loss: 3.4110, train_acc: 0.2268, val_acc: 0.1989
[20231206-042057] [INFO] elapsed_time: 72.45 min
[20231206-042424] [INFO] Epoch: 22, train_loss: 2.9238, val_loss: 3.3542, train_acc: 0.2438, val_acc: 0.2113
[20231206-042424] [INFO] elapsed_time: 75.90 min
[20231206-042751] [INFO] Epoch: 23, train_loss: 2.8663, val_loss: 3.9147, train_acc: 0.2498, val_acc: 0.1540
[20231206-042751] [INFO] elapsed_time: 79.34 min
[20231206-043118] [INFO] Epoch: 24, train_loss: 2.8689, val_loss: 3.4941, train_acc: 0.2519, val_acc: 0.2016
[20231206-043118] [INFO] elapsed_time: 82.79 min
[20231206-043444] [INFO] Epoch: 25, train_loss: 2.8297, val_loss: 3.2741, train_acc: 0.2583, val_acc: 0.2233
[20231206-043444] [INFO] elapsed_time: 86.24 min
[20231206-043811] [INFO] Epoch: 26, train_loss: 2.6968, val_loss: 3.6306, train_acc: 0.2819, val_acc: 0.2186
[20231206-043811] [INFO] elapsed_time: 89.68 min
[20231206-044138] [INFO] Epoch: 27, train_loss: 2.6735, val_loss: 3.9507, train_acc: 0.2906, val_acc: 0.2034
[20231206-044138] [INFO] elapsed_time: 93.12 min
[20231206-044505] [INFO] Epoch: 28, train_loss: 2.5928, val_loss: 3.2681, train_acc: 0.3020, val_acc: 0.2395
[20231206-044505] [INFO] elapsed_time: 96.57 min
[20231206-044832] [INFO] Epoch: 29, train_loss: 2.5973, val_loss: 3.4993, train_acc: 0.3074, val_acc: 0.2166
[20231206-044832] [INFO] elapsed_time: 100.03 min
[20231206-045159] [INFO] Epoch: 30, train_loss: 2.5188, val_loss: 3.3387, train_acc: 0.3223, val_acc: 0.2493
[20231206-045159] [INFO] elapsed_time: 103.48 min
[20231206-045526] [INFO] Epoch: 31, train_loss: 2.4349, val_loss: 3.3730, train_acc: 0.3388, val_acc: 0.2404
[20231206-045526] [INFO] elapsed_time: 106.93 min
[20231206-045853] [INFO] Epoch: 32, train_loss: 2.4007, val_loss: 3.2803, train_acc: 0.3498, val_acc: 0.2541
[20231206-045853] [INFO] elapsed_time: 110.37 min
[20231206-050220] [INFO] Epoch: 33, train_loss: 2.4231, val_loss: 3.3662, train_acc: 0.3363, val_acc: 0.2352
[20231206-050220] [INFO] elapsed_time: 113.82 min
[20231206-050547] [INFO] Epoch: 34, train_loss: 2.4051, val_loss: 3.3033, train_acc: 0.3483, val_acc: 0.2396
[20231206-050547] [INFO] elapsed_time: 117.27 min
[20231206-050913] [INFO] Epoch: 35, train_loss: 2.2901, val_loss: 3.3335, train_acc: 0.3704, val_acc: 0.2633
[20231206-050913] [INFO] elapsed_time: 120.72 min
[20231206-051240] [INFO] Epoch: 36, train_loss: 2.2422, val_loss: 3.2016, train_acc: 0.3845, val_acc: 0.2673
[20231206-051240] [INFO] elapsed_time: 124.17 min
[20231206-051607] [INFO] Epoch: 37, train_loss: 2.2216, val_loss: 3.2594, train_acc: 0.3836, val_acc: 0.2694
[20231206-051607] [INFO] elapsed_time: 127.61 min
[20231206-051934] [INFO] Epoch: 38, train_loss: 2.2320, val_loss: 3.2994, train_acc: 0.3853, val_acc: 0.2633
[20231206-051934] [INFO] elapsed_time: 131.05 min
[20231206-052300] [INFO] Epoch: 39, train_loss: 2.1845, val_loss: 3.1540, train_acc: 0.3998, val_acc: 0.2856
[20231206-052300] [INFO] elapsed_time: 134.50 min
[20231206-052628] [INFO] Epoch: 40, train_loss: 2.1377, val_loss: 3.1655, train_acc: 0.4054, val_acc: 0.2871
[20231206-052628] [INFO] elapsed_time: 137.96 min
[20231206-052954] [INFO] Epoch: 41, train_loss: 2.1104, val_loss: 3.2588, train_acc: 0.4143, val_acc: 0.2875
[20231206-052954] [INFO] elapsed_time: 141.40 min
[20231206-053321] [INFO] Epoch: 42, train_loss: 2.0338, val_loss: 3.2925, train_acc: 0.4351, val_acc: 0.2939
[20231206-053321] [INFO] elapsed_time: 144.84 min
[20231206-053648] [INFO] Epoch: 43, train_loss: 2.1553, val_loss: 3.3358, train_acc: 0.4065, val_acc: 0.2868
[20231206-053648] [INFO] elapsed_time: 148.29 min
[20231206-054015] [INFO] Epoch: 44, train_loss: 1.9844, val_loss: 2.9855, train_acc: 0.4423, val_acc: 0.3260
[20231206-054015] [INFO] elapsed_time: 151.75 min
[20231206-054342] [INFO] Epoch: 45, train_loss: 1.9285, val_loss: 3.1735, train_acc: 0.4507, val_acc: 0.3117
[20231206-054342] [INFO] elapsed_time: 155.19 min
[20231206-054708] [INFO] Epoch: 46, train_loss: 1.9019, val_loss: 3.1179, train_acc: 0.4654, val_acc: 0.3147
[20231206-054708] [INFO] elapsed_time: 158.63 min
[20231206-055035] [INFO] Epoch: 47, train_loss: 1.8717, val_loss: 3.2027, train_acc: 0.4750, val_acc: 0.3099
[20231206-055035] [INFO] elapsed_time: 162.08 min
[20231206-055402] [INFO] Epoch: 48, train_loss: 1.8688, val_loss: 3.3348, train_acc: 0.4723, val_acc: 0.2987
[20231206-055402] [INFO] elapsed_time: 165.53 min
[20231206-055728] [INFO] Epoch: 49, train_loss: 1.8617, val_loss: 3.1632, train_acc: 0.4788, val_acc: 0.3254
[20231206-055728] [INFO] elapsed_time: 168.96 min
[20231206-060055] [INFO] Epoch: 50, train_loss: 1.8094, val_loss: 3.4994, train_acc: 0.4890, val_acc: 0.2937
[20231206-060055] [INFO] elapsed_time: 172.40 min
[20231206-060421] [INFO] Epoch: 51, train_loss: 1.7787, val_loss: 3.2515, train_acc: 0.5000, val_acc: 0.3050
[20231206-060421] [INFO] elapsed_time: 175.85 min
[20231206-060748] [INFO] Epoch: 52, train_loss: 1.7990, val_loss: 3.2834, train_acc: 0.4914, val_acc: 0.2997
[20231206-060748] [INFO] elapsed_time: 179.29 min
[20231206-061116] [INFO] Epoch: 53, train_loss: 1.7228, val_loss: 3.0775, train_acc: 0.5180, val_acc: 0.3285
[20231206-061116] [INFO] elapsed_time: 182.77 min
[20231206-061443] [INFO] Epoch: 54, train_loss: 1.7199, val_loss: 3.4259, train_acc: 0.5171, val_acc: 0.2933
[20231206-061443] [INFO] elapsed_time: 186.21 min
[20231206-061809] [INFO] Epoch: 55, train_loss: 1.7302, val_loss: 3.4071, train_acc: 0.5186, val_acc: 0.3290
[20231206-061809] [INFO] elapsed_time: 189.65 min
[20231206-062136] [INFO] Epoch: 56, train_loss: 1.6658, val_loss: 3.3297, train_acc: 0.5283, val_acc: 0.3219
[20231206-062136] [INFO] elapsed_time: 193.10 min
[20231206-062503] [INFO] Epoch: 57, train_loss: 1.5846, val_loss: 3.4665, train_acc: 0.5541, val_acc: 0.3293
[20231206-062503] [INFO] elapsed_time: 196.54 min
[20231206-062829] [INFO] Epoch: 58, train_loss: 1.5732, val_loss: 3.4889, train_acc: 0.5606, val_acc: 0.3385
[20231206-062829] [INFO] elapsed_time: 199.98 min
[20231206-063156] [INFO] Epoch: 59, train_loss: 1.5449, val_loss: 3.6683, train_acc: 0.5701, val_acc: 0.3232
[20231206-063156] [INFO] elapsed_time: 203.43 min
[20231206-063523] [INFO] Epoch: 60, train_loss: 1.6053, val_loss: 3.6645, train_acc: 0.5514, val_acc: 0.3155
[20231206-063523] [INFO] elapsed_time: 206.88 min
[20231206-063850] [INFO] Epoch: 61, train_loss: 1.5155, val_loss: 3.9230, train_acc: 0.5736, val_acc: 0.3360
[20231206-063850] [INFO] elapsed_time: 210.33 min
[20231206-064217] [INFO] Epoch: 62, train_loss: 1.4923, val_loss: 3.6701, train_acc: 0.5830, val_acc: 0.3253
[20231206-064217] [INFO] elapsed_time: 213.78 min
[20231206-064545] [INFO] Epoch: 63, train_loss: 1.4631, val_loss: 3.6163, train_acc: 0.5915, val_acc: 0.3472
[20231206-064545] [INFO] elapsed_time: 217.24 min
[20231206-064911] [INFO] Epoch: 64, train_loss: 1.4147, val_loss: 3.4860, train_acc: 0.6104, val_acc: 0.3624
[20231206-064911] [INFO] elapsed_time: 220.68 min
[20231206-065238] [INFO] Epoch: 65, train_loss: 1.4098, val_loss: 3.6958, train_acc: 0.6089, val_acc: 0.3442
[20231206-065238] [INFO] elapsed_time: 224.13 min
[20231206-065605] [INFO] Epoch: 66, train_loss: 1.3896, val_loss: 3.6197, train_acc: 0.6118, val_acc: 0.3619
[20231206-065605] [INFO] elapsed_time: 227.57 min
[20231206-065932] [INFO] Epoch: 67, train_loss: 1.3993, val_loss: 3.5271, train_acc: 0.6093, val_acc: 0.3548
[20231206-065932] [INFO] elapsed_time: 231.03 min
[20231206-070259] [INFO] Epoch: 68, train_loss: 1.3766, val_loss: 3.5984, train_acc: 0.6220, val_acc: 0.3622
[20231206-070259] [INFO] elapsed_time: 234.47 min
[20231206-070625] [INFO] Epoch: 69, train_loss: 1.3584, val_loss: 3.3934, train_acc: 0.6252, val_acc: 0.3523
[20231206-070625] [INFO] elapsed_time: 237.92 min
[20231206-070625] [INFO] Early Stopping with Epoch: 68
[20231206-070626] [INFO] argument
[20231206-070626] [INFO]   note: None
[20231206-070626] [INFO]   seed: 24771
[20231206-070626] [INFO]   dir_result: ResNet50/lr3e-4_b512
[20231206-070626] [INFO]   model_name: ResNet50
[20231206-070626] [INFO]   num_epoch: 100
[20231206-070626] [INFO]   batch_size: 512
[20231206-070626] [INFO]   lr: 0.0003
[20231206-070626] [INFO]   patience: 25
[20231206-070626] [INFO]   delta: 0.002
[20231206-070626] [INFO]   lr_min: 1e-05
[20231206-070626] [INFO]   warmup_t: 10
[20231206-070626] [INFO]   warmup_lr_init: 1e-05
[20231206-070626] [INFO] loss
[20231206-070626] [INFO]   training: True
[20231206-070626] [INFO]   reduction: mean
[20231206-070626] [INFO]   ignore_index: -100
[20231206-070626] [INFO]   label_smoothing: 0.0
[20231206-070626] [INFO] optimizer
[20231206-070626] [INFO]   defaults: {'lr': 0.0003, 'betas': (0.9, 0.999), 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False, 'maximize': False, 'foreach': None, 'capturable': False, 'differentiable': False, 'fused': None}
[20231206-070626] [INFO] scheduler
[20231206-070626] [INFO]   optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0003
    lr: 0.00011893996636109602
    maximize: False
    weight_decay: 0
)
[20231206-070626] [INFO]   param_group_field: lr
[20231206-070626] [INFO]   base_values: [0.0003]
[20231206-070626] [INFO]   metric: None
[20231206-070626] [INFO]   t_in_epochs: True
[20231206-070626] [INFO]   noise_range_t: None
[20231206-070626] [INFO]   noise_pct: 0.67
[20231206-070626] [INFO]   noise_type: normal
[20231206-070626] [INFO]   noise_std: 1.0
[20231206-070626] [INFO]   noise_seed: 42
[20231206-070626] [INFO]   t_initial: 100
[20231206-070626] [INFO]   lr_min: 1e-05
[20231206-070626] [INFO]   cycle_mul: 1.0
[20231206-070626] [INFO]   cycle_decay: 1.0
[20231206-070626] [INFO]   cycle_limit: 1
[20231206-070626] [INFO]   warmup_t: 10
[20231206-070626] [INFO]   warmup_lr_init: 1e-05
[20231206-070626] [INFO]   warmup_prefix: True
[20231206-070626] [INFO]   k_decay: 1.0
[20231206-070626] [INFO]   warmup_steps: [2.8999999999999993e-05]
